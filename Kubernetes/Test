task 7 = 
a. Create a deployment deploy01 with the image nginx and port 80 exposed:
kubectl create deployment deploy01 --image=nginx --port=80

b. Update the deployment deploy01 with the image nginx:dev and record the execution:
kubectl set image deployment/deploy01 nginx=nginx:dev --record=true

c. If the deployment in step b is unsuccessful, rollback the deployment to the previous state:
kubectl rollout undo deployment/deploy01

d. If the Nginx deployment is in a healthy state, scale the deployment to run 3 replicas and record the execution:
kubectl scale deployment/deploy01 --replicas=3 --record=true

e. Display the history of deployment deploy01 and store it in a file named /opt/answers/31.txt:
kubectl rollout history deployment/deploy01 > /opt/answers/31.txt

These commands will help you create, update, rollback, scale, and record the history of the deploy01 deployment as per your requirements.

----------------------------------------------------------


apiVersion:

Subfield: Specifies the API version for the Kubernetes resource.
Usage: Indicates which version of the Kubernetes API the resource adheres to. Different API versions may have varying features and capabilities.

kind:
Subfield: Specifies the type of Kubernetes resource being defined (e.g., Deployment, Pod, Service).
Usage: Identifies the type of resource the YAML file describes, guiding how Kubernetes should treat it.

metadata:
Subfields: name, namespace, labels, annotations, and more.
Usage: Contains metadata about the resource, such as its name, namespace (optional), labels (key-value pairs for categorization), and annotations (additional information).

spec:
Subfields: Varies depending on the resource type (e.g., containers, volumes, replicas, ports, etc.).
Usage: Contains the desired state and configuration for the resource. The subfields within spec are specific to the resource type.

containers:
Subfields: name, image, ports, command, args, and more.
Usage: Describes the containers to run within a Pod. You specify the container name, the Docker image to use, ports to expose, and optionally, the command and arguments for the container.

volumes:
Subfields: name, persistentVolumeClaim, emptyDir, hostPath, and more.
Usage: Defines storage volumes that can be mounted into containers. These volumes can be used to store and share data between containers and across restarts.

replicas:
Subfield: Specifies the desired number of replicas for a resource (e.g., Deployment, ReplicaSet).
Usage: Indicates how many instances of a resource, like Pods, should be maintained. Useful for achieving high availability and load balancing.

ports:
Subfields: containerPort, name, protocol, targetPort, and more.
Usage: Defines the network ports to expose for communication. It includes details like the container port, target port, and protocol (e.g., TCP or UDP).

selector:
Subfield: Specifies the criteria for selecting Pods (e.g., labels).
Usage: Used in resources like Services and Deployments to determine which Pods to include or route traffic to based on their labels.

strategy:
Subfields: type, rollingUpdate, and more (used in Deployments).
Usage: Configures the deployment strategy, including rolling updates, to control how new versions of an application are rolled out.

serviceType:
Subfield: Specifies the type of Service (e.g., ClusterIP, NodePort, LoadBalancer).
Usage: Determines how the Service should be exposed outside the cluster or within the cluster network.

volumeClaimTemplates:
Subfields: metadata and spec.
Usage: Used in StatefulSets to define how Persistent Volume Claims (PVCs) should be created and bound to Pods.
These fields and subfields are the building blocks of Kubernetes resource configurations. Depending on the specific resource you're defining (e.g., Pod, Deployment, Service), you'll use these fields to describe the desired state of your application or infrastructure in the cluster.


-------------------------------------------------------

To create a pod that uses secrets in Kubernetes, you can configure secrets in two different ways:

a. Pull secrets from environment variables:

First, create a secret containing your sensitive data. For example, let's create a secret named "my-secret" with a key "password":
kubectl create secret generic my-secret --from-literal=password=supersecret

Now, create a pod that uses this secret in environment variables:

apiVersion: v1
kind: Pod
metadata:
  name: secret-env-pod
spec:
  containers:
  - name: secret-env-container
    image: nginx
    env:
    - name: MY_PASSWORD
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: password


b. Pull secrets from a volume:
You can create a secret and mount it as a volume in a pod. Here's an example:

yaml
Copy code
apiVersion: v1
kind: Pod
metadata:
  name: secret-volume-pod
spec:
  containers:
  - name: secret-volume-container
    image: nginx
    volumeMounts:
    - name: secret-volume
      mountPath: /etc/secrets
  volumes:
  - name: secret-volume
    secret:
      secretName: my-secret


In both cases, the secret "my-secret" is being used, either as environment variables (MY_PASSWORD) or mounted as a volume at /etc/secrets.

c. Dump the secrets using kubectl:

You can use kubectl to check that your secrets are available in the pod. For example, to check the environment variable in the first pod:
kubectl exec secret-env-pod -- env | grep MY_PASSWORD

And to check the content of the mounted volume in the second pod:
kubectl exec secret-volume-pod -- cat /etc/secrets/password

These commands will show that the secrets are accessible in the respective pods


------------------------------------------------------------


how Kubernetes (K8s) architecture works when you create a Pod or Deployment, step by step, using an example:

Example Scenario: Creating a simple Deployment with one Pod.

1. User Interaction:

You, the user, interact with Kubernetes either through the command-line tool kubectl, a graphical interface, or an automation script.
You submit a YAML file or use a command to create a Deployment. For example:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-container
          image: nginx
          
You issue the command: kubectl apply -f my-deployment.yaml.


2. API Server:
Your request is sent to the Kubernetes API Server, which is the control center of the Kubernetes cluster.
The API Server receives your request and performs authentication and authorization checks to ensure you have the necessary permissions to create the resource.

3. etcd (Cluster-Wide Key-Value Store):
The API Server stores the configuration for your Deployment in etcd, which is a distributed, consistent key-value store used to store all cluster data.
etcd acts as the source of truth for the cluster's state.

4. Controller Manager:
The Deployment controller in the Controller Manager watches the etcd store for changes to resources, such as Deployments.
Upon detecting the new Deployment resource, the controller calculates the desired state (in this case, three replicas of your Pod).

5. Scheduler:
The Scheduler is responsible for deciding where to place new Pods.
It evaluates the available worker nodes' resources and constraints and selects the most suitable node for the new Pods.

6. Kubelet (on Selected Node):
The Kubelet on the selected worker node receives instructions from the API Server to create Pods.
It starts the necessary containers on that node, according to the Pod specification.
In our example, it would start three replicas of the nginx container as specified in the Deployment.

7. Container Runtime (e.g., Docker):
The Container Runtime (e.g., Docker) on the node creates and manages the containers as requested by the Kubelet.
It pulls the specified container image (in this case, nginx) from a container registry if it's not already present on the node.

8. Running Pods:
After containers are created, your Pods are up and running on the selected node.

9. Service Discovery (Optional):
If you have defined a Service resource to expose your Deployment, Kubernetes sets up the necessary networking rules to enable service discovery and load balancing for your Pods.

10. Cluster Networking (e.g., CNI):
- If you're using a network plugin like the Container Network Interface (CNI), it ensures that Pods can communicate with each other across nodes in the cluster.

11. User Access:
- Your deployed application is now accessible according to the service type you defined (ClusterIP, NodePort, LoadBalancer, etc.) and any networking configurations you've set up.

In summary, when you create a Pod or Deployment in Kubernetes, your request goes through a series of components, including the API Server, etcd, Controller Manager, Scheduler, Kubelet, and Container Runtime, to bring your application to life. Kubernetes manages the entire lifecycle of your application, ensuring that it runs as desired and is highly available.



